{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### prepare.py\n",
        "\n",
        "import torch.utils.data as utils\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def PrepareDataset(speed_matrix, BATCH_SIZE=48, seq_len=12, pred_len=12, train_propotion=0.7, valid_propotion=0.1):\n",
        "    time_len = speed_matrix.shape[0]\n",
        "    max_speed = speed_matrix.max().max()\n",
        "    min_speed = speed_matrix.min().min()\n",
        "    speed_matrix = (speed_matrix - min_speed)/(max_speed - min_speed)\n",
        "\n",
        "    speed_sequences, speed_labels = [], []\n",
        "    for i in range(time_len - seq_len - pred_len):\n",
        "        speed_sequences.append(speed_matrix.iloc[i:i + seq_len].values)\n",
        "        speed_labels.append(speed_matrix.iloc[i + seq_len:i + seq_len + pred_len].values)\n",
        "    speed_sequences, speed_labels = np.asarray(speed_sequences), np.asarray(speed_labels)\n",
        "\n",
        "    speed_labels = speed_labels.reshape(speed_labels.shape[0], seq_len, -1)\n",
        "\n",
        "    sample_size = speed_sequences.shape[0]\n",
        "\n",
        "    train_index = int(np.floor(sample_size * train_propotion))\n",
        "    valid_index = int(np.floor(sample_size * (train_propotion + valid_propotion)))\n",
        "\n",
        "    train_data, train_label = speed_sequences[:train_index], speed_labels[:train_index]\n",
        "    valid_data, valid_label = speed_sequences[train_index:valid_index], speed_labels[train_index:valid_index]\n",
        "    test_data, test_label = speed_sequences[valid_index:], speed_labels[valid_index:]\n",
        "\n",
        "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
        "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
        "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
        "\n",
        "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
        "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
        "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
        "\n",
        "    train_dataloader = utils.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "    test_dataloader = utils.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "    return train_dataloader, valid_dataloader, test_dataloader, max_speed"
      ],
      "metadata": {
        "id": "Le-odSqAnKSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### modules.py\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "import math\n",
        "\n",
        "\n",
        "class DynamicFilterGNN(nn.Module):\n",
        "    def __init__(self, in_features, out_features, filter_adjacency_matrix, bias=True):\n",
        "        super(DynamicFilterGNN, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.base_filter = nn.Parameter(torch.Tensor(in_features, in_features))\n",
        "\n",
        "        use_gpu = torch.cuda.is_available()\n",
        "        self.filter_adjacency_matrix = None\n",
        "        #self.base_filter = nn.Parameter(torch.Tensor(in_features, in_features))\n",
        "        if use_gpu:\n",
        "            self.filter_adjacency_matrix = Variable(filter_adjacency_matrix.cuda(), requires_grad=False)\n",
        "        else:\n",
        "            self.filter_adjacency_matrix = Variable(filter_adjacency_matrix, requires_grad=False)\n",
        "\n",
        "        self.transform = nn.Linear(in_features, in_features)\n",
        "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        self.base_filter.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input):\n",
        "        transformed_filter = self.transform(self.base_filter)\n",
        "        transformed_adjacency = 0.9*self.filter_adjacency_matrix+0.1*transformed_filter\n",
        "        result_embed = F.linear(input, transformed_adjacency.matmul(self.weight), self.bias)\n",
        "        #F.linear(input, transformed_adjacency.matmul(self.weight), self.bias)\n",
        "        return result_embed\n",
        "\n",
        "\n",
        "    def get_transformed_adjacency(self):\n",
        "        transformed_filter = self.transform(self.base_filter)\n",
        "        transformed_adjacency = 0.9 * self.filter_adjacency_matrix + 0.1 * transformed_filter\n",
        "        return transformed_adjacency\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "               + 'in_features=' + str(self.in_features) \\\n",
        "               + ', out_features=' + str(self.out_features) \\\n",
        "               + ', bias=' + str(self.bias is not None) + ')'\n",
        "\n"
      ],
      "metadata": {
        "id": "uQFJtmPznlfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STGMamba.py\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from einops import rearrange, repeat, einsum\n",
        "from typing import Union\n",
        "\n",
        "\n",
        "# KFGN (Kalman Filtering Graph Neural Networks) Model\n",
        "class KFGN(nn.Module):\n",
        "    def __init__(self, K, A, feature_size, Clamp_A=True):\n",
        "        super(KFGN, self).__init__()\n",
        "        self.feature_size = feature_size\n",
        "        self.hidden_size = feature_size\n",
        "        self.K = K\n",
        "        self.A_list = []\n",
        "\n",
        "        D_inverse = torch.diag(1 / torch.sum(A, 0))\n",
        "        norm_A = torch.matmul(D_inverse, A)\n",
        "        A = norm_A\n",
        "\n",
        "        A_temp = torch.eye(feature_size, feature_size)\n",
        "        for i in range(K):\n",
        "            A_temp = torch.matmul(A_temp, A)\n",
        "            if Clamp_A:\n",
        "                A_temp = torch.clamp(A_temp, max=1.)\n",
        "            self.A_list.append(A_temp)\n",
        "\n",
        "        self.gc_list = nn.ModuleList([DynamicFilterGNN(feature_size, feature_size, self.A_list[i], bias=False) for i in range(K)])\n",
        "        hidden_size = self.feature_size\n",
        "        gc_input_size = self.feature_size * K\n",
        "\n",
        "        self.fl = nn.Linear(gc_input_size + hidden_size, hidden_size)\n",
        "        self.il = nn.Linear(gc_input_size + hidden_size, hidden_size)\n",
        "        self.ol = nn.Linear(gc_input_size + hidden_size, hidden_size)\n",
        "        self.Cl = nn.Linear(gc_input_size + hidden_size, hidden_size)\n",
        "\n",
        "\n",
        "        self.Neighbor_weight = Parameter(torch.FloatTensor(feature_size))\n",
        "        stdv = 1. / math.sqrt(feature_size)\n",
        "        self.Neighbor_weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "        input_size = self.feature_size\n",
        "\n",
        "        self.rfl = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.ril = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.rol = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.rCl = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "        # addtional vars\n",
        "        self.c = torch.nn.Parameter(torch.Tensor([1]))\n",
        "\n",
        "        self.fc1 = nn.Linear(64, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size, 64)\n",
        "        self.fc5 = nn.Linear(64, hidden_size)\n",
        "        self.fc6 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc7 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc8 = nn.Linear(hidden_size, 64)\n",
        "\n",
        "    def forward(self, input, Hidden_State=None, Cell_State=None, rHidden_State=None, rCell_State=None):\n",
        "        batch_size, time_steps, _ = input.shape\n",
        "        if Hidden_State is None:\n",
        "            Hidden_State = Variable(torch.zeros(batch_size,self.feature_size).cuda())\n",
        "        if Cell_State is None:\n",
        "            Cell_State = Variable(torch.zeros(batch_size,self.feature_size).cuda())\n",
        "        if rHidden_State is None:\n",
        "            rHidden_State = Variable(torch.zeros(batch_size,self.feature_size).cuda())\n",
        "        if rCell_State is None:\n",
        "            rCell_State = Variable(torch.zeros(batch_size,self.feature_size).cuda())\n",
        "\n",
        "        Hidden_State = Hidden_State.unsqueeze(1).expand(-1, time_steps, -1)\n",
        "        Cell_State = Cell_State.unsqueeze(1).expand(-1, time_steps, -1)\n",
        "        rHidden_State = rHidden_State.unsqueeze(1).expand(-1, time_steps, -1)\n",
        "        rCell_State = rCell_State.unsqueeze(1).expand(-1, time_steps, -1)\n",
        "\n",
        "        x = input\n",
        "        gc = self.gc_list[0](x)\n",
        "        for i in range(1, self.K):\n",
        "            gc = torch.cat((gc, self.gc_list[i](x)), 1)\n",
        "\n",
        "        combined = torch.cat((gc, Hidden_State), 1)\n",
        "        dim1=combined.shape[0]\n",
        "        dim2=combined.shape[1]\n",
        "        dim3=combined.shape[2]\n",
        "        combined=combined.view(dim1,dim2//4,dim3*4)\n",
        "\n",
        "        f = torch.sigmoid(self.fl(combined))\n",
        "        i = torch.sigmoid(self.il(combined))\n",
        "        o = torch.sigmoid(self.ol(combined))\n",
        "        C = torch.tanh(self.Cl(combined))\n",
        "\n",
        "        NC = torch.mul(Cell_State,\n",
        "                       torch.mv(Variable(self.A_list[-1], requires_grad=False).cuda(), self.Neighbor_weight))\n",
        "        Cell_State = f * NC + i * C\n",
        "        Hidden_State = o * torch.tanh(Cell_State)\n",
        "\n",
        "        # LSTM\n",
        "        rcombined = torch.cat((input, rHidden_State), 1)\n",
        "        d1=rcombined.shape[0]\n",
        "        d2=rcombined.shape[1]\n",
        "        d3=rcombined.shape[2]\n",
        "        rcombined=rcombined.view(d1,d2//2,d3*2)\n",
        "        rf = torch.sigmoid(self.rfl(rcombined))\n",
        "        ri = torch.sigmoid(self.ril(rcombined))\n",
        "        ro = torch.sigmoid(self.rol(rcombined))\n",
        "        rC = torch.tanh(self.rCl(rcombined))\n",
        "        rCell_State = rf * rCell_State + ri * rC\n",
        "        rHidden_State = ro * torch.tanh(rCell_State)\n",
        "\n",
        "        # Kalman Filtering\n",
        "        var1, var2 = torch.var(input), torch.var(gc)\n",
        "\n",
        "        pred = (Hidden_State * var1 * self.c + rHidden_State * var2) / (var1 + var2 * self.c)\n",
        "\n",
        "        return pred\n",
        "        #return Hidden_State, Cell_State, gc, rHidden_State, rCell_State, pred\n",
        "\n",
        "    def Bi_torch(self, a):\n",
        "        a[a < 0] = 0\n",
        "        a[a > 0] = 1\n",
        "        return a\n",
        "\n",
        "    def loop(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "        time_step = inputs.size(1)\n",
        "        Hidden_State, Cell_State, rHidden_State, rCell_State = self.initHidden(batch_size)\n",
        "        for i in range(time_step):\n",
        "            Hidden_State, Cell_State, gc, rHidden_State, rCell_State, pred = self.forward(\n",
        "                torch.squeeze(inputs[:, i:i + 1, :]), Hidden_State, Cell_State, rHidden_State, rCell_State)\n",
        "        return pred\n",
        "\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        use_gpu = torch.cuda.is_available()\n",
        "        if use_gpu:\n",
        "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
        "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
        "            rHidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
        "            rCell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
        "            return Hidden_State, Cell_State, rHidden_State, rCell_State\n",
        "        else:\n",
        "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
        "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
        "            rHidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
        "            rCell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
        "            return Hidden_State, Cell_State, rHidden_State, rCell_State\n",
        "\n",
        "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
        "        use_gpu = torch.cuda.is_available()\n",
        "        if use_gpu:\n",
        "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
        "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
        "            rHidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
        "            rCell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
        "            return Hidden_State, Cell_State, rHidden_State, rCell_State\n",
        "        else:\n",
        "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
        "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
        "            rHidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
        "            rCell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
        "            return Hidden_State, Cell_State, rHidden_State, rCell_State\n",
        "\n",
        "# Mamba Network\n",
        "@dataclass\n",
        "class ModelArgs:\n",
        "    d_model: int\n",
        "    n_layer: int\n",
        "    features: int\n",
        "    d_state: int = 16\n",
        "    expand: int = 2\n",
        "    dt_rank: Union[int, str] = 'auto'\n",
        "    d_conv: int = 4\n",
        "    conv_bias: bool = True\n",
        "    bias: bool = False\n",
        "    K: int = 3\n",
        "    A: torch.Tensor = None\n",
        "    feature_size: int = None\n",
        "\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.d_inner = int(self.expand * self.d_model)\n",
        "        if self.dt_rank == 'auto':\n",
        "            self.dt_rank = math.ceil(self.d_model / 16)\n",
        "\n",
        "class KFGN_Mamba(nn.Module):\n",
        "    def __init__(self, args: ModelArgs):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.kfgn = KFGN(K=args.K, A=args.A, feature_size=args.feature_size)\n",
        "        self.encode = nn.Linear(args.features, args.d_model)\n",
        "        self.encoder_layers = nn.ModuleList([ResidualBlock(args,self.kfgn) for _ in range(args.n_layer)])\n",
        "        self.encoder_norm = RMSNorm(args.d_model)\n",
        "        # Decoder (identical to Encoder)\n",
        "        ##self.decoder_layers = nn.ModuleList([ResidualBlock(args) for _ in range(args.n_layer)]) #You can optionally uncommand these lines to use the identical Decoder.\n",
        "        ##self.decoder_norm = RMSNorm(args.d_model) #You can optionally uncommand these lines to use the identical Decoder.\n",
        "        self.decode = nn.Linear(args.d_model, args.features)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.encode(input_ids)\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x)\n",
        "        x = self.encoder_norm(x)\n",
        "        # Decoder\n",
        "        ##for layer in self.decoder_layers:#You can optionally uncommand these lines to use the identical Decoder.\n",
        "        ##    x = layer(x) #You can optionally uncommand these lines to use the identical Decoder.\n",
        "        ##x = self.decoder_norm(x) #You can optionally uncommand these lines to use the identical Decoder.\n",
        "\n",
        "        # Output\n",
        "        x = self.decode(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Residual Block in Mamba Model\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, args: ModelArgs, kfgn: KFGN):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.kfgn = KFGN(K=args.K, A=args.A, feature_size=args.feature_size)\n",
        "        self.ggel = GraphormerGraphEncoderLayer()\n",
        "        self.mixer = MambaBlock(args,kfgn)\n",
        "        self.norm = RMSNorm(args.d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = x\n",
        "        x1 = self.norm(x)\n",
        "        x2 = self.kfgn(x1)\n",
        "        x3 = self.ggel(x2)[0]\n",
        "        x4 = self.mixer(x3)\n",
        "        output = x4 + x1\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class MambaBlock(nn.Module):\n",
        "    def __init__(self, args: ModelArgs, kfgn: KFGN):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.kfgn = kfgn\n",
        "\n",
        "        self.in_proj = nn.Linear(args.d_model, args.d_inner * 2, bias=args.bias)\n",
        "\n",
        "        self.conv1d = nn.Conv1d(\n",
        "            in_channels=args.d_inner,\n",
        "            out_channels=args.d_inner,\n",
        "            bias=args.conv_bias,\n",
        "            kernel_size=args.d_conv,\n",
        "            groups=args.d_inner,\n",
        "            padding=args.d_conv - 1,\n",
        "        )\n",
        "\n",
        "        self.x_proj = nn.Linear(args.d_inner, args.dt_rank + args.d_state * 2, bias=False)\n",
        "\n",
        "        self.dt_proj = nn.Linear(args.dt_rank, args.d_inner, bias=True)\n",
        "\n",
        "        A = repeat(torch.arange(1, args.d_state + 1), 'n -> d n', d=args.d_inner)\n",
        "        self.A_log = nn.Parameter(torch.log(A))\n",
        "        self.D = nn.Parameter(torch.ones(args.d_inner))\n",
        "        self.out_proj = nn.Linear(args.d_inner, args.d_model, bias=args.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        (b, l, d) = x.shape\n",
        "\n",
        "        x_and_res = self.in_proj(x)\n",
        "        (x, res) = x_and_res.split(split_size=[self.args.d_inner, self.args.d_inner], dim=-1)\n",
        "\n",
        "        x = rearrange(x, 'b l d_in -> b d_in l')\n",
        "        x = self.conv1d(x)[:, :, :l]\n",
        "        x = rearrange(x, 'b d_in l -> b l d_in')\n",
        "\n",
        "        x = F.silu(x)\n",
        "\n",
        "        y = self.ssm(x)\n",
        "\n",
        "        y = y * F.silu(res)\n",
        "\n",
        "        output = self.out_proj(y)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def ssm(self, x):\n",
        "        (d_in, n) = self.A_log.shape\n",
        "\n",
        "        A = -torch.exp(self.A_log.float())\n",
        "        D = self.D.float()\n",
        "\n",
        "        x_dbl = self.x_proj(x)\n",
        "\n",
        "        (delta, B, C) = x_dbl.split(split_size=[self.args.dt_rank, n, n], dim=-1)\n",
        "        delta = F.softplus(self.dt_proj(delta))  # (b, l, d_in)\n",
        "\n",
        "        y = self.selective_scan(x, delta, A, B, C, D)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "    def selective_scan(self, u, delta, A, B, C, D):\n",
        "        (b, l, d_in) = u.shape\n",
        "        n = A.shape[1]\n",
        "        # This is the new version of Selective Scan Algorithm named as \"Graph Selective Scan\"\n",
        "        #In Graph Selective Scan, we use the Feed-Forward graph information from KFGN, and incorporate the Feed-Forward information with \"delta\"\n",
        "        temp_adj = self.kfgn.gc_list[-1].get_transformed_adjacency()\n",
        "        temp_adj_padded = torch.ones(d_in, d_in, device=temp_adj.device)\n",
        "        temp_adj_padded[:temp_adj.size(0), :temp_adj.size(1)] = temp_adj\n",
        "\n",
        "        delta_p = torch.matmul(delta,temp_adj_padded)\n",
        "\n",
        "        # The fused param delta_p will participate in the following upgrading of deltaA and deltaB_u\n",
        "        deltaA = torch.exp(einsum(delta_p, A, 'b l d_in, d_in n -> b l d_in n'))\n",
        "        deltaB_u = einsum(delta_p, B, u, 'b l d_in, b l n, b l d_in -> b l d_in n')\n",
        "\n",
        "        x = torch.zeros((b, d_in, n), device=deltaA.device)\n",
        "        ys = []\n",
        "        for i in range(l):\n",
        "            x = deltaA[:, i] * x + deltaB_u[:, i]\n",
        "            y = einsum(x, C[:, i, :], 'b d_in n, b n -> b d_in')\n",
        "            ys.append(y)\n",
        "        y = torch.stack(ys, dim=1)  # shape (b, l, d_in)\n",
        "\n",
        "        y = y + u * D\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(d_model))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
        "\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "2LGB4WYWnek0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import LayerNorm\n",
        "\n",
        "\n",
        "class GraphormerGraphEncoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            embedding_dim: int = 307,\n",
        "            ffn_embedding_dim: int = 3072,\n",
        "            num_attention_heads: int = 1,\n",
        "            dropout: float = 0.1,\n",
        "            attention_dropout: float = 0.1,\n",
        "            activation_dropout: float = 0.1,\n",
        "            activation_fn: str = \"gelu\",\n",
        "            export: bool = False,\n",
        "            init_fn: Callable = None,\n",
        "            pre_layernorm: bool = True,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if init_fn is not None:\n",
        "            init_fn()\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.attention_dropout = attention_dropout\n",
        "        self.pre_layernorm = pre_layernorm\n",
        "\n",
        "        self.dropout_module = nn.Dropout(dropout)\n",
        "        self.activation_dropout_module = nn.Dropout(activation_dropout)\n",
        "\n",
        "        self.activation_fn = nn.GELU() if activation_fn == \"gelu\" else nn.ReLU()\n",
        "\n",
        "        self.self_attn = MultiheadAttention(\n",
        "            self.embedding_dim,\n",
        "            num_attention_heads,\n",
        "            dropout=attention_dropout,\n",
        "            self_attention=True,\n",
        "        )\n",
        "\n",
        "        # layer norm associated with the self attention layer\n",
        "        self.self_attn_layer_norm = LayerNorm(self.embedding_dim, eps=1e-8)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.embedding_dim, ffn_embedding_dim)\n",
        "        self.fc2 = nn.Linear(ffn_embedding_dim, self.embedding_dim)\n",
        "\n",
        "        # layer norm associated with the position wise feed-forward NN\n",
        "        self.final_layer_norm = LayerNorm(self.embedding_dim, eps=1e-8)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            x: torch.Tensor,\n",
        "            self_attn_bias: Optional[torch.Tensor] = None,\n",
        "            self_attn_mask: Optional[torch.Tensor] = None,\n",
        "            self_attn_padding_mask: Optional[torch.Tensor] = None,\n",
        "            get_attn_scores=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        LayerNorm is applied either before or after the self-attention/ffn\n",
        "        modules similar to the original Transformer implementation.\n",
        "        \"\"\"\n",
        "        # x: T x B x C\n",
        "        residual = x\n",
        "        if self.pre_layernorm:\n",
        "            x = self.self_attn_layer_norm(x)\n",
        "        x, attn = self.self_attn(\n",
        "            query=x,\n",
        "            key=x,\n",
        "            value=x,\n",
        "            attn_bias=self_attn_bias,\n",
        "            key_padding_mask=self_attn_padding_mask,\n",
        "            need_weights=get_attn_scores,\n",
        "            attn_mask=self_attn_mask,\n",
        "        )\n",
        "        x = self.dropout_module(x)\n",
        "        x = residual + x\n",
        "        if not self.pre_layernorm:\n",
        "            x = self.self_attn_layer_norm(x)\n",
        "\n",
        "        residual = x\n",
        "        if self.pre_layernorm:\n",
        "            x = self.final_layer_norm(x)\n",
        "        x = self.activation_fn(self.fc1(x))\n",
        "        x = self.activation_dropout_module(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout_module(x)\n",
        "        x = residual + x\n",
        "        if not self.pre_layernorm:\n",
        "            x = self.final_layer_norm(x)\n",
        "        return x, attn"
      ],
      "metadata": {
        "id": "H3XPN_60oyOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import Tensor, nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            embed_dim,\n",
        "            num_heads,\n",
        "            kdim=None,\n",
        "            vdim=None,\n",
        "            dropout=0.0,\n",
        "            bias=True,\n",
        "            self_attention=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.kdim = kdim if kdim is not None else embed_dim\n",
        "        self.vdim = vdim if vdim is not None else embed_dim\n",
        "        self.qkv_same_dim = self.kdim == embed_dim and self.vdim == embed_dim\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_module = nn.Dropout(dropout)\n",
        "\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        assert (\n",
        "                self.head_dim * num_heads == self.embed_dim\n",
        "        ), \"embed_dim must be divisible by num_heads\"\n",
        "        self.scaling = self.head_dim ** -0.5\n",
        "\n",
        "        self.self_attention = self_attention\n",
        "\n",
        "        assert self.self_attention, \"Only support self attention\"\n",
        "\n",
        "        assert not self.self_attention or self.qkv_same_dim, (\n",
        "            \"Self-attention requires query, key and \" \"value to be of the same size\"\n",
        "        )\n",
        "\n",
        "        self.k_proj = nn.Linear(self.kdim, embed_dim, bias=bias)\n",
        "        self.v_proj = nn.Linear(self.vdim, embed_dim, bias=bias)\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.qkv_same_dim:\n",
        "            # Empirically observed the convergence to be much better with\n",
        "            # the scaled initialization\n",
        "            nn.init.xavier_uniform_(self.k_proj.weight, gain=1 / math.sqrt(2))\n",
        "            nn.init.xavier_uniform_(self.v_proj.weight, gain=1 / math.sqrt(2))\n",
        "            nn.init.xavier_uniform_(self.q_proj.weight, gain=1 / math.sqrt(2))\n",
        "        else:\n",
        "            nn.init.xavier_uniform_(self.k_proj.weight)\n",
        "            nn.init.xavier_uniform_(self.v_proj.weight)\n",
        "            nn.init.xavier_uniform_(self.q_proj.weight)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.out_proj.weight)\n",
        "        if self.out_proj.bias is not None:\n",
        "            nn.init.constant_(self.out_proj.bias, 0.0)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            query,\n",
        "            key: Optional[Tensor],\n",
        "            value: Optional[Tensor],\n",
        "            attn_bias: Optional[Tensor],\n",
        "            key_padding_mask: Optional[Tensor] = None,\n",
        "            need_weights: bool = True,\n",
        "            attn_mask: Optional[Tensor] = None,\n",
        "            before_softmax: bool = False,\n",
        "            need_head_weights: bool = False,\n",
        "    ) -> Tuple[Tensor, Optional[Tensor]]:\n",
        "        \"\"\"Input shape: Time x Batch x Channel\n",
        "\n",
        "        Args:\n",
        "            key_padding_mask (ByteTensor, optional): mask to exclude\n",
        "                keys that are pads, of shape `(batch, src_len)`, where\n",
        "                padding elements are indicated by 1s.\n",
        "            need_weights (bool, optional): return the attention weights,\n",
        "                averaged over heads (default: False).\n",
        "            attn_mask (ByteTensor, optional): typically used to\n",
        "                implement causal attention, where the mask prevents the\n",
        "                attention from looking forward in time (default: None).\n",
        "            before_softmax (bool, optional): return the raw attention\n",
        "                weights and values before the attention softmax.\n",
        "            need_head_weights (bool, optional): return the attention\n",
        "                weights for each head. Implies *need_weights*. Default:\n",
        "                return the average attention weights over all heads.\n",
        "        \"\"\"\n",
        "        if need_head_weights:\n",
        "            need_weights = True\n",
        "\n",
        "        tgt_len, bsz, embed_dim = query.size()\n",
        "        src_len = tgt_len\n",
        "        assert embed_dim == self.embed_dim, f\"query dim {embed_dim} != {self.embed_dim}\"\n",
        "        assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
        "        if key is not None:\n",
        "            src_len, key_bsz, _ = key.size()\n",
        "            if not torch.jit.is_scripting():\n",
        "                assert key_bsz == bsz\n",
        "                assert value is not None\n",
        "                assert src_len, bsz == value.shape[:2]\n",
        "\n",
        "        q = self.q_proj(query)\n",
        "        k = self.k_proj(query)\n",
        "        v = self.v_proj(query)\n",
        "        q *= self.scaling\n",
        "\n",
        "        q = (\n",
        "            q.contiguous()\n",
        "            .view(tgt_len, bsz * self.num_heads, self.head_dim)\n",
        "            .transpose(0, 1)\n",
        "        )\n",
        "        if k is not None:\n",
        "            k = (\n",
        "                k.contiguous()\n",
        "                .view(-1, bsz * self.num_heads, self.head_dim)\n",
        "                .transpose(0, 1)\n",
        "            )\n",
        "        if v is not None:\n",
        "            v = (\n",
        "                v.contiguous()\n",
        "                .view(-1, bsz * self.num_heads, self.head_dim)\n",
        "                .transpose(0, 1)\n",
        "            )\n",
        "\n",
        "        assert k is not None\n",
        "        assert k.size(1) == src_len\n",
        "\n",
        "        # This is part of a workaround to get around fork/join parallelism\n",
        "        # not supporting Optional types.\n",
        "        if key_padding_mask is not None and key_padding_mask.dim() == 0:\n",
        "            key_padding_mask = None\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            assert key_padding_mask.size(0) == bsz\n",
        "            assert key_padding_mask.size(1) == src_len\n",
        "        attn_weights = torch.bmm(q, k.contiguous().transpose(1, 2))\n",
        "        attn_weights = self.apply_sparse_mask(attn_weights, tgt_len, src_len, bsz)\n",
        "\n",
        "        assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
        "\n",
        "        if attn_bias is not None:\n",
        "            attn_weights += attn_bias.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_mask = attn_mask.unsqueeze(0)\n",
        "            attn_weights += attn_mask\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            # don't attend to padding symbols\n",
        "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            attn_weights = attn_weights.masked_fill(\n",
        "                key_padding_mask.unsqueeze(1).unsqueeze(2).to(torch.bool),\n",
        "                float(\"-inf\"),\n",
        "            )\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        if before_softmax:\n",
        "            return attn_weights, v\n",
        "\n",
        "        attn_weights_float = F.softmax(\n",
        "            attn_weights, dim=-1\n",
        "        )\n",
        "        attn_weights = attn_weights_float.type_as(attn_weights)\n",
        "        attn_probs = self.dropout_module(attn_weights)\n",
        "\n",
        "        assert v is not None\n",
        "        attn = torch.bmm(attn_probs, v)\n",
        "        assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
        "\n",
        "        attn = attn.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
        "        attn = self.out_proj(attn)\n",
        "\n",
        "        attn_weights: Optional[Tensor] = None\n",
        "        if need_weights:\n",
        "            attn_weights = attn_weights_float.contiguous().view(\n",
        "                bsz, self.num_heads, tgt_len, src_len\n",
        "            ).transpose(1, 0)\n",
        "            if not need_head_weights:\n",
        "                # average attention weights over heads\n",
        "                attn_weights = attn_weights.mean(dim=0)\n",
        "\n",
        "        return attn, attn_weights\n",
        "\n",
        "    def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):\n",
        "        return attn_weights\n",
        "\n",
        "    def upgrade_state_dict_named(self, state_dict, name):\n",
        "        prefix = name + \".\" if name != \"\" else \"\"\n",
        "        items_to_add = {}\n",
        "        keys_to_remove = []\n",
        "        for k in state_dict.keys():\n",
        "            if k.endswith(prefix + \"in_proj_weight\"):\n",
        "                # in_proj_weight used to be q + k + v with same dimensions\n",
        "                dim = int(state_dict[k].shape[0] / 3)\n",
        "                items_to_add[prefix + \"q_proj.weight\"] = state_dict[k][:dim]\n",
        "                items_to_add[prefix + \"k_proj.weight\"] = state_dict[k][dim: 2 * dim]\n",
        "                items_to_add[prefix + \"v_proj.weight\"] = state_dict[k][2 * dim:]\n",
        "\n",
        "                keys_to_remove.append(k)\n",
        "\n",
        "                k_bias = prefix + \"in_proj_bias\"\n",
        "                if k_bias in state_dict.keys():\n",
        "                    dim = int(state_dict[k].shape[0] / 3)\n",
        "                    items_to_add[prefix + \"q_proj.bias\"] = state_dict[k_bias][:dim]\n",
        "                    items_to_add[prefix + \"k_proj.bias\"] = state_dict[k_bias][\n",
        "                                                           dim: 2 * dim\n",
        "                                                           ]\n",
        "                    items_to_add[prefix + \"v_proj.bias\"] = state_dict[k_bias][2 * dim:]\n",
        "\n",
        "                    keys_to_remove.append(prefix + \"in_proj_bias\")\n",
        "\n",
        "        for k in keys_to_remove:\n",
        "            del state_dict[k]\n",
        "\n",
        "        for key, value in items_to_add.items():\n",
        "            state_dict[key] = value"
      ],
      "metadata": {
        "id": "JAM3GhAykpzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### train_STGmamba.py\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.autograd import Variable\n",
        "\n",
        "y = []  # by me\n",
        "\n",
        "def TrainSTG_Mamba(train_dataloader, valid_dataloader, A, K=3, num_epochs=1, mamba_features=307):\n",
        "    # 'mamba_features=184' if we use Knowair dataset;\n",
        "    # 'mamba_features=307' if we use PEMS04 datastet;\n",
        "    # 'mamba_features=80' if we use HZ_Metro dataset;\n",
        "    inputs, labels = next(iter(train_dataloader))\n",
        "    [batch_size, step_size, fea_size] = inputs.size()\n",
        "    input_dim = fea_size\n",
        "    hidden_dim = fea_size\n",
        "    output_dim = fea_size\n",
        "\n",
        "    kfgn_mamba_args = ModelArgs(\n",
        "        K=K,\n",
        "        A=torch.Tensor(A),\n",
        "        feature_size=A.shape[0],\n",
        "        d_model=fea_size,  # hidden_dim is fea_size\n",
        "        n_layer=4,\n",
        "        features=mamba_features\n",
        "    )\n",
        "\n",
        "    kfgn_mamba = KFGN_Mamba(kfgn_mamba_args)\n",
        "    kfgn_mamba.cuda()\n",
        "\n",
        "    loss_MSE = torch.nn.MSELoss()\n",
        "    loss_L1 = torch.nn.L1Loss()\n",
        "\n",
        "    learning_rate = 1e-4\n",
        "    optimizer = optim.AdamW(kfgn_mamba.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01, amsgrad=False)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-5)\n",
        "\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "\n",
        "    interval = 100\n",
        "    losses_train = []\n",
        "    losses_interval_train = []\n",
        "    losses_valid = []\n",
        "    losses_interval_valid = []\n",
        "    losses_epoch = []  # Initialize the list for epoch losses\n",
        "\n",
        "    cur_time = time.time()\n",
        "    pre_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        trained_number = 0\n",
        "\n",
        "        valid_dataloader_iter = iter(valid_dataloader)\n",
        "\n",
        "        for data in train_dataloader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            if inputs.shape[0] != batch_size:\n",
        "                continue\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "            kfgn_mamba.zero_grad()\n",
        "\n",
        "            labels = torch.squeeze(labels)\n",
        "            pred = kfgn_mamba(inputs)  # Updated to use new model directly\n",
        "\n",
        "            loss_train = loss_MSE(pred, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "            # Update learning rate by CosineAnnealingLR\n",
        "            scheduler.step()\n",
        "\n",
        "            losses_train.append(loss_train.data)\n",
        "\n",
        "            # validation\n",
        "            try:\n",
        "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
        "            except StopIteration:\n",
        "                valid_dataloader_iter = iter(valid_dataloader)\n",
        "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs_val, labels_val = Variable(inputs_val.cuda()), Variable(labels_val.cuda())\n",
        "            else:\n",
        "                inputs_val, labels_val = Variable(inputs_val), Variable(labels_val)\n",
        "\n",
        "            labels_val = torch.squeeze(labels_val)\n",
        "\n",
        "            pred = kfgn_mamba(inputs_val)\n",
        "            loss_valid = loss_MSE(pred, labels_val)\n",
        "            losses_valid.append(loss_valid.data)\n",
        "\n",
        "            trained_number += 1\n",
        "\n",
        "            if trained_number % interval == 0:\n",
        "                cur_time = time.time()\n",
        "                loss_interval_train = np.around(sum(losses_train[-interval:]).cpu().numpy() / interval, decimals=8)\n",
        "                losses_interval_train.append(loss_interval_train)\n",
        "                loss_interval_valid = np.around(sum(losses_valid[-interval:]).cpu().numpy() / interval, decimals=8)\n",
        "                losses_interval_valid.append(loss_interval_valid)\n",
        "                print('Iteration #: {}, train_loss: {}, valid_loss: {}, time: {}'.format(\n",
        "                    trained_number * batch_size,\n",
        "                    loss_interval_train,\n",
        "                    loss_interval_valid,\n",
        "                    np.around([cur_time - pre_time], decimals=8)))\n",
        "                pre_time = cur_time\n",
        "\n",
        "        loss_epoch = loss_valid.cpu().data.numpy()\n",
        "        losses_epoch.append(loss_epoch)\n",
        "\n",
        "    return kfgn_mamba, [losses_train, losses_interval_train, losses_valid, losses_interval_valid]\n",
        "\n",
        "\n",
        "\n",
        "def TestSTG_Mamba(kfgn_mamba, test_dataloader, max_speed):\n",
        "    inputs, labels = next(iter(test_dataloader))\n",
        "    [batch_size, step_size, fea_size] = inputs.size()\n",
        "\n",
        "    cur_time = time.time()\n",
        "    pre_time = time.time()\n",
        "\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "\n",
        "    loss_MSE = torch.nn.MSELoss()\n",
        "    loss_L1 = torch.nn.L1Loss()\n",
        "\n",
        "    tested_batch = 0\n",
        "\n",
        "    losses_mse = []\n",
        "    losses_l1 = []\n",
        "    MAEs = []\n",
        "    MAPEs = []\n",
        "    MSEs = []\n",
        "    RMSEs = []\n",
        "    VARs = []\n",
        "\n",
        "    #predictions = []\n",
        "    #ground_truths = []\n",
        "\n",
        "    for data in test_dataloader:\n",
        "        inputs, labels = data\n",
        "\n",
        "        if inputs.shape[0] != batch_size:\n",
        "            continue\n",
        "\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        pred = kfgn_mamba(inputs)\n",
        "        labels = torch.squeeze(labels)\n",
        "\n",
        "        loss_mse = F.mse_loss(pred, labels)\n",
        "        loss_l1 = F.l1_loss(pred, labels)\n",
        "        MAE = torch.mean(torch.abs(pred - torch.squeeze(labels)))\n",
        "        MAPE = torch.mean(torch.abs(pred - torch.squeeze(labels)) / torch.abs(torch.squeeze(labels)))\n",
        "        # Calculate MAPE only for non-zero labels\n",
        "        non_zero_labels = torch.abs(labels) > 0\n",
        "        if torch.any(non_zero_labels):\n",
        "            MAPE_values = torch.abs(pred - torch.squeeze(labels)) / torch.abs(torch.squeeze(labels))\n",
        "            MAPE = torch.mean(MAPE_values[non_zero_labels])\n",
        "            MAPEs.append(MAPE.item())\n",
        "\n",
        "        MSE = torch.mean((torch.squeeze(labels) - pred)**2)\n",
        "        RMSE = math.sqrt(torch.mean((torch.squeeze(labels) - pred)**2))\n",
        "        VAR = 1-(torch.var(torch.squeeze(labels)-pred))/torch.var(torch.squeeze(labels))\n",
        "\n",
        "        losses_mse.append(loss_mse.item())\n",
        "        losses_l1.append(loss_l1.item())\n",
        "        MAEs.append(MAE.item())\n",
        "        MAPEs.append(MAPE.item())\n",
        "        MSEs.append(MSE.item())\n",
        "        RMSEs.append(RMSE)\n",
        "        VARs.append(VAR.item())\n",
        "\n",
        "        # Reshape pred to 2D before creating DataFrame\n",
        "        #predictions.append(pd.DataFrame(pred.cpu().data.numpy().reshape(-1, fea_size)))\n",
        "        #ground_truths.append(pd.DataFrame(labels.cpu().data.numpy()))\n",
        "        y.append(pred.cpu().data.numpy())  # by me\n",
        "\n",
        "        tested_batch += 1\n",
        "\n",
        "        if tested_batch % 100 == 0:\n",
        "            cur_time = time.time()\n",
        "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format(\n",
        "                tested_batch * batch_size,\n",
        "                np.around([loss_l1.data[0]], decimals=8),\n",
        "                np.around([loss_mse.data[0]], decimals=8),\n",
        "                np.around([cur_time - pre_time], decimals=8)))\n",
        "            pre_time = cur_time\n",
        "\n",
        "    losses_l1 = np.array(losses_l1)\n",
        "    losses_mse = np.array(losses_mse)\n",
        "    MAEs = np.array(MAEs)\n",
        "    MAPEs = np.array(MAPEs)\n",
        "    MSEs = np.array(MSEs)\n",
        "    RMSEs = np.array(RMSEs)\n",
        "    VARs = np.array(VARs)\n",
        "\n",
        "    mean_l1 = np.mean(losses_l1) * max_speed\n",
        "    std_l1 = np.std(losses_l1) * max_speed\n",
        "    mean_mse = np.mean(losses_mse) * max_speed\n",
        "    MAE_ = np.mean(MAEs) * max_speed\n",
        "    std_MAE_ = np.std(MAEs) * max_speed\n",
        "    MAPE_ = np.mean(MAPEs) * 100\n",
        "    MSE_ = np.mean(MSEs) * (max_speed ** 2)\n",
        "    RMSE_ = np.mean(RMSEs) * max_speed\n",
        "    VAR_ = np.mean(VARs)\n",
        "    results = [MAE_, std_MAE_, MAPE_, MSE_, RMSE_, VAR_]\n",
        "\n",
        "    print('Tested: MAE: {}, std_MAE: {}, MAPE: {}, MSE: {}, RMSE: {}, VAR: {}'.format(MAE_, std_MAE_, MAPE_, MSE_, RMSE_, VAR_))\n",
        "    return results"
      ],
      "metadata": {
        "id": "78QzalCqjAlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### main.py\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "print(\"\\nLoading PEMS04 data...\")\n",
        "speed_matrix = pd.read_csv('pems04_flow.csv',sep=',')\n",
        "A = np.load('pems04_adj.npy')\n",
        "\n",
        "\n",
        "print(\"\\nPreparing train/test data...\")\n",
        "train_dataloader, valid_dataloader, test_dataloader, max_value = PrepareDataset(speed_matrix, BATCH_SIZE=48)\n",
        "\n",
        "print(\"\\nTraining STGmambomer model...\")\n",
        "STGmamba, STGmamba_loss = TrainSTG_Mamba(train_dataloader, valid_dataloader, A, K=3, num_epochs=25, mamba_features=307)\n",
        "print(\"\\nTesting STGmambomer model...\")\n",
        "results = TestSTG_Mamba(STGmamba, test_dataloader, max_value)"
      ],
      "metadata": {
        "id": "z4YRyEW8e_-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c062be3c-b2fb-496b-97d4-3b9795e117aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading PEMS04 data...\n",
            "\n",
            "Preparing train/test data...\n",
            "\n",
            "Training STGmambomer model...\n",
            "Epoch 0/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.06145928055047989, valid_loss: 0.057434480637311935, time: [18.18432283]\n",
            "Epoch 1/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0265390295535326, valid_loss: 0.02738039940595627, time: [17.19266438]\n",
            "Epoch 2/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0187078807502985, valid_loss: 0.019805679097771645, time: [17.00969744]\n",
            "Epoch 3/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.007810300216078758, valid_loss: 0.008453129790723324, time: [17.64439344]\n",
            "Epoch 4/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.006085020024329424, valid_loss: 0.00660277996212244, time: [17.82154536]\n",
            "Epoch 5/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0052610901184380054, valid_loss: 0.00574075011536479, time: [17.16548729]\n",
            "Epoch 6/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.004652759991586208, valid_loss: 0.0051303100772202015, time: [17.26841211]\n",
            "Epoch 7/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.004298279993236065, valid_loss: 0.004701910074800253, time: [17.18491578]\n",
            "Epoch 8/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.004013550002127886, valid_loss: 0.004415920004248619, time: [17.41120124]\n",
            "Epoch 9/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.003844579914584756, valid_loss: 0.004200569819658995, time: [17.13559628]\n",
            "Epoch 10/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0036166401114314795, valid_loss: 0.003976049832999706, time: [17.47134018]\n",
            "Epoch 11/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.003476090030744672, valid_loss: 0.003836170071735978, time: [17.28537416]\n",
            "Epoch 12/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.003358379937708378, valid_loss: 0.003720379900187254, time: [17.28137422]\n",
            "Epoch 13/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.003275139955803752, valid_loss: 0.0036076500546187162, time: [17.24587202]\n",
            "Epoch 14/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0031514600850641727, valid_loss: 0.0035091100726276636, time: [17.14975739]\n",
            "Epoch 15/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0030858900863677263, valid_loss: 0.003454929916188121, time: [17.45780826]\n",
            "Epoch 16/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0029720799066126347, valid_loss: 0.0033321098890155554, time: [17.21287274]\n",
            "Epoch 17/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0029277100693434477, valid_loss: 0.0032834699377417564, time: [17.75707507]\n",
            "Epoch 18/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.002875050064176321, valid_loss: 0.0032383198849856853, time: [17.34275699]\n",
            "Epoch 19/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.002781759947538376, valid_loss: 0.0031669700983911753, time: [17.55324888]\n",
            "Epoch 20/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.002700410084798932, valid_loss: 0.0030947800260037184, time: [17.37654018]\n",
            "Epoch 21/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0026827899273484945, valid_loss: 0.0030716098845005035, time: [17.60191584]\n",
            "Epoch 22/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.002643449930474162, valid_loss: 0.0030356599017977715, time: [17.56495214]\n",
            "Epoch 23/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0025549300480633974, valid_loss: 0.0029494198970496655, time: [17.49836254]\n",
            "Epoch 24/24\n",
            "----------\n",
            "Iteration #: 4800, train_loss: 0.0025035699363797903, valid_loss: 0.0028925600927323103, time: [17.71778035]\n",
            "\n",
            "Testing STGmambomer model...\n",
            "Tested: MAE: 28.360110746118526, std_MAE: 0.8475435133114346, MAPE: 26.40765951625232, MSE: 1643.874963910062, RMSE: 40.52967858675297, VAR: 0.9219240690099781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mvqljAR5jqmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}